{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install googletrans"
      ],
      "metadata": {
        "id": "MvGuwLzCNKYj",
        "outputId": "973bd115-b973-4aab-e127-dd6dd05cd30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.13.2)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the uploaded Excel file\n",
        "file_path = \"./Group1.xlsx\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Read all sheet names (each sheet is a group)\n",
        "sheet_names = xls.sheet_names\n",
        "\n",
        "# Read all sheets into a dictionary, skipping the first row\n",
        "vocab_groups = {sheet: xls.parse(sheet, skiprows=1) for sheet in sheet_names}\n",
        "\n",
        "df = vocab_groups['Sheet1']\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0F-bSQFwQVW",
        "outputId": "d0d2f7ed-484f-48f6-afdd-8b7ed68c0cef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Words  Synonym1  Synonym2  Synonym3  Korean\n",
            "0         abound       NaN       NaN       NaN     NaN\n",
            "1      amorphous       NaN       NaN       NaN     NaN\n",
            "2        austere       NaN       NaN       NaN     NaN\n",
            "3          belie       NaN       NaN       NaN     NaN\n",
            "4     capricious       NaN       NaN       NaN     NaN\n",
            "5       cerebral       NaN       NaN       NaN     NaN\n",
            "6      congenial       NaN       NaN       NaN     NaN\n",
            "7    conspicuous       NaN       NaN       NaN     NaN\n",
            "8        cursory       NaN       NaN       NaN     NaN\n",
            "9       daunting       NaN       NaN       NaN     NaN\n",
            "10         deify       NaN       NaN       NaN     NaN\n",
            "11      didactic       NaN       NaN       NaN     NaN\n",
            "12   disseminate       NaN       NaN       NaN     NaN\n",
            "13      feasible       NaN       NaN       NaN     NaN\n",
            "14         flout       NaN       NaN       NaN     NaN\n",
            "15   homogeneous       NaN       NaN       NaN     NaN\n",
            "16       humdrum       NaN       NaN       NaN     NaN\n",
            "17       insipid       NaN       NaN       NaN     NaN\n",
            "18    loquacious       NaN       NaN       NaN     NaN\n",
            "19  misanthropic       NaN       NaN       NaN     NaN\n",
            "20      misnomer       NaN       NaN       NaN     NaN\n",
            "21     negligent       NaN       NaN       NaN     NaN\n",
            "22    obsequious       NaN       NaN       NaN     NaN\n",
            "23       placate       NaN       NaN       NaN     NaN\n",
            "24    proclivity       NaN       NaN       NaN     NaN\n",
            "25       puerile       NaN       NaN       NaN     NaN\n",
            "26      quixotic       NaN       NaN       NaN     NaN\n",
            "27   spendthrift       NaN       NaN       NaN     NaN\n",
            "28      taciturn       NaN       NaN       NaN     NaN\n",
            "29          wary       NaN       NaN       NaN     NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = df['Words'].tolist()\n",
        "\n",
        "# Translate each word into Korean using googletrans\n",
        "from googletrans import Translator\n",
        "\n",
        "translator = Translator()\n",
        "translations = [translator.translate(word, src='en', dest='ko').text for word in words]\n",
        "\n",
        "# Add translations back to the DataFrame\n",
        "df.loc[1:len(translations), 'Unnamed: 4'] = translations\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Translated Words\", dataframe=df)"
      ],
      "metadata": {
        "id": "FgsjZH_9M3AN",
        "outputId": "5d579eb2-6755-444a-919f-50b00f228d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abound', 'amorphous', 'austere', 'belie', 'capricious', 'cerebral', 'congenial', 'conspicuous', 'cursory', 'daunting', 'deify', 'didactic', 'disseminate', 'feasible', 'flout', 'homogeneous', 'humdrum', 'insipid', 'loquacious', 'misanthropic', 'misnomer', 'negligent', 'obsequious', 'placate', 'proclivity', 'puerile', 'quixotic', 'spendthrift', 'taciturn', 'wary']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'coroutine' object has no attribute 'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4bf1b5f1b289>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ko'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Add translations back to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4bf1b5f1b289>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ko'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Add translations back to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'text'"
          ]
        }
      ]
    }
  ]
}